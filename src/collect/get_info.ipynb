{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from requests import Request, Session\n",
    "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import JSON\n",
    "\n",
    "from binance.spot import Spot \n",
    "\n",
    "# handle data\n",
    "import pyspark.sql as ps\n",
    "from pyspark.sql.functions import from_unixtime,date_format,from_utc_timestamp\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# train data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "# enviroment\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../../env/app.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get token details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare api routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "COIN_MARKET_CAP_KEY = os.environ.get(\"COIN_MARKET_CAP_KEY\")\n",
    "API_URL = 'https://pro-api.coinmarketcap.com'\n",
    "\n",
    "META_DATA_ROUTE = '/v2/cryptocurrency/info'\n",
    "LIST_SYMBOLS_ROUTE = '/v1/cryptocurrency/map'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "  'Accepts': 'application/json',\n",
    "  'X-CMC_PRO_API_KEY': COIN_MARKET_CAP_KEY,\n",
    "}\n",
    "session = Session()\n",
    "session.headers.update(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = session.get(API_URL + LIST_SYMBOLS_ROUTE)\n",
    "data = json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.code.notebook.error": {
       "message": "o.endsWith is not a function",
       "name": "TypeError",
       "stack": "TypeError: o.endsWith is not a function\n    at c (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/extensions/ipynb/dist/ipynbMain.js:1:142764)\n    at i (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/extensions/ipynb/dist/ipynbMain.js:1:143414)\n    at l (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/extensions/ipynb/dist/ipynbMain.js:1:144222)\n    at h (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/extensions/ipynb/dist/ipynbMain.js:1:144972)\n    at Array.map (<anonymous>)\n    at /private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/extensions/ipynb/dist/ipynbMain.js:1:146140\n    at /private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/extensions/ipynb/dist/ipynbMain.js:1:146457\n    at /private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/extensions/ipynb/dist/ipynbMain.js:1:146464\n    at Array.map (<anonymous>)\n    at e.jupyterNotebookModelToNotebookData (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/extensions/ipynb/dist/ipynbMain.js:1:145716)\n    at e.NotebookSerializer.deserializeNotebook (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/extensions/ipynb/dist/ipynbMain.js:1:156342)\n    at f.$dataToNotebook (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:94:98450)\n    at l._doInvokeHandler (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:102:13680)\n    at l._invokeHandler (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:102:13362)\n    at l._receiveRequest (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:102:12081)\n    at l._receiveOneMessage (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:102:11033)\n    at /private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:102:8941\n    at h.invoke (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:61:145)\n    at v.deliver (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:61:2266)\n    at g.fire (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:61:1844)\n    at r.fire (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:70:16515)\n    at /private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:118:17104\n    at h.invoke (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:61:145)\n    at v.deliver (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:61:2266)\n    at g.fire (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:61:1844)\n    at r.fire (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:70:16515)\n    at o._receiveMessage (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:70:21327)\n    at /private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:70:18770\n    at h.invoke (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:61:145)\n    at v.deliver (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:61:2266)\n    at g.fire (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:61:1844)\n    at g.acceptChunk (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:70:13346)\n    at /private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:70:12476\n    at Socket.i (/private/var/folders/p7/08wxvf195r35gt2pw893ynsw0000gn/T/AppTranslocation/E55F4488-E953-4E31-B4E7-E43B59B10C0D/d/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/api/node/extensionHostProcess.js:70:24594)\n    at Socket.emit (node:events:526:28)\n    at addChunk (node:internal/streams/readable:315:12)\n    at readableAddChunk (node:internal/streams/readable:289:9)\n    at Socket.Readable.push (node:internal/streams/readable:228:10)\n    at Pipe.onStreamRead (node:internal/stream_base_commons:190:23)"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON(data[\"data\"][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = list(map(lambda info: info[\"symbol\"],data[\"data\"]) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2124\n",
      "['ETHBTC', 'LTCBTC', 'BNBBTC', 'NEOBTC', 'QTUMETH', 'EOSETH', 'SNTETH', 'BNTETH', 'BCCBTC', 'GASBTC']\n"
     ]
    }
   ],
   "source": [
    "print(len(symbols))\n",
    "print(symbols[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch detail of each symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "  'symbol':\",\".join(symbols[:1060]),\n",
    "  'aux': \"description,tags,date_added\"\n",
    "}\n",
    "\n",
    "response = session.get(API_URL + META_DATA_ROUTE, params=parameters)\n",
    "data = json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(data):\n",
    "    items = list(map(lambda item: item[1][0],data.items()))\n",
    "    rows = list(map(lambda item: list(map(lambda k_v: k_v[1],item.items())) ,items))\n",
    "    cols = list(map(lambda k_v: k_v[0],items[0].items()))\n",
    "    \n",
    "    return rows,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = get_table(data[\"data\"])\n",
    "df = pd.DataFrame(rows, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>symbol</th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>slug</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>tags</th>\n",
       "      <th>tag-names</th>\n",
       "      <th>tag-groups</th>\n",
       "      <th>date_added</th>\n",
       "      <th>twitter_username</th>\n",
       "      <th>is_hidden</th>\n",
       "      <th>date_launched</th>\n",
       "      <th>contract_address</th>\n",
       "      <th>self_reported_circulating_supply</th>\n",
       "      <th>self_reported_tags</th>\n",
       "      <th>self_reported_market_cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>42-coin</td>\n",
       "      <td>42</td>\n",
       "      <td>coin</td>\n",
       "      <td>42-coin (42) is a cryptocurrency . Users are a...</td>\n",
       "      <td>42-coin</td>\n",
       "      <td></td>\n",
       "      <td>[mineable, hybrid-pow-pos, scrypt, store-of-va...</td>\n",
       "      <td>[Mineable, Hybrid - PoW &amp; PoS, Scrypt, Store O...</td>\n",
       "      <td>[OTHERS, ALGORITHM, ALGORITHM, CATEGORY]</td>\n",
       "      <td>2014-01-14T00:00:00.000Z</td>\n",
       "      <td>42newchain</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'contract_address': '0x73cf73c2503154de4dc12...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2837</td>\n",
       "      <td>0xBitcoin</td>\n",
       "      <td>0xBTC</td>\n",
       "      <td>token</td>\n",
       "      <td>0xBitcoin (0xBTC) is a cryptocurrency and oper...</td>\n",
       "      <td>0xbtc</td>\n",
       "      <td>0xbitcoin</td>\n",
       "      <td>[mineable, arbitrum-ecosytem]</td>\n",
       "      <td>[Mineable, Arbitrum Ecosystem]</td>\n",
       "      <td>[OTHERS, PLATFORM]</td>\n",
       "      <td>2018-06-04T00:00:00.000Z</td>\n",
       "      <td>0xBTCFoundation</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'contract_address': '0xb6ed7644c69416d67b522...</td>\n",
       "      <td>8183550.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.896847e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2601</td>\n",
       "      <td>1World</td>\n",
       "      <td>1WO</td>\n",
       "      <td>token</td>\n",
       "      <td>1World (1WO) is a cryptocurrency and operates ...</td>\n",
       "      <td>1world</td>\n",
       "      <td></td>\n",
       "      <td>[algorand-ecosystem]</td>\n",
       "      <td>[Algorand Ecosystem]</td>\n",
       "      <td>[CATEGORY]</td>\n",
       "      <td>2018-03-21T00:00:00.000Z</td>\n",
       "      <td>1World_Online</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'contract_address': '0xfdbc1adc26f0f8f8606a5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1252</td>\n",
       "      <td>2GIVE</td>\n",
       "      <td>2GIVE</td>\n",
       "      <td>coin</td>\n",
       "      <td>2GIVE (2GIVE) is a cryptocurrency . Users are ...</td>\n",
       "      <td>2give</td>\n",
       "      <td>2GIVE</td>\n",
       "      <td>[mineable, hybrid-pow-pos, scrypt]</td>\n",
       "      <td>[Mineable, Hybrid - PoW &amp; PoS, Scrypt]</td>\n",
       "      <td>[OTHERS, ALGORITHM, ALGORITHM]</td>\n",
       "      <td>2016-05-16T00:00:00.000Z</td>\n",
       "      <td>2GiveCoin</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3287</td>\n",
       "      <td>Abulaba</td>\n",
       "      <td>AAA</td>\n",
       "      <td>token</td>\n",
       "      <td>Abulaba (AAA) is a cryptocurrency and operates...</td>\n",
       "      <td>abulaba</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-09-14T00:00:00.000Z</td>\n",
       "      <td>AbulabaCapital</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'contract_address': '0xd938137e6d96c72e4a608...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>1896</td>\n",
       "      <td>0x</td>\n",
       "      <td>ZRX</td>\n",
       "      <td>token</td>\n",
       "      <td>0x (ZRX) is a cryptocurrency and operates on t...</td>\n",
       "      <td>0x</td>\n",
       "      <td>0xProject</td>\n",
       "      <td>[platform, decentralized-exchange-dex-token, d...</td>\n",
       "      <td>[Platform, Decentralized Exchange (DEX) Token,...</td>\n",
       "      <td>[CATEGORY, CATEGORY, CATEGORY, CATEGORY, CATEG...</td>\n",
       "      <td>2017-08-16T00:00:00.000Z</td>\n",
       "      <td>0xproject</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'contract_address': '0xe41d2489571d322189246...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>2047</td>\n",
       "      <td>Zeusshield</td>\n",
       "      <td>ZSC</td>\n",
       "      <td>token</td>\n",
       "      <td>Zeusshield (ZSC) is a cryptocurrency and opera...</td>\n",
       "      <td>zeusshield</td>\n",
       "      <td></td>\n",
       "      <td>[asset-management, ai-big-data]</td>\n",
       "      <td>[Asset Management, AI &amp; Big Data]</td>\n",
       "      <td>[INDUSTRY, INDUSTRY]</td>\n",
       "      <td>2017-10-13T00:00:00.000Z</td>\n",
       "      <td>Zeusshield</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'contract_address': '0x7A41e0517a5ecA4FdbC7F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>4826</td>\n",
       "      <td>ZUM TOKEN</td>\n",
       "      <td>ZUM</td>\n",
       "      <td>token</td>\n",
       "      <td>ZUM TOKEN (ZUM) is a cryptocurrency launched i...</td>\n",
       "      <td>zum-token</td>\n",
       "      <td></td>\n",
       "      <td>[ethereum-ecosystem, bnb-chain]</td>\n",
       "      <td>[Ethereum Ecosystem, BNB Chain]</td>\n",
       "      <td>[PLATFORM, PLATFORM]</td>\n",
       "      <td>2019-10-25T00:00:00.000Z</td>\n",
       "      <td>Zum_Token</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-09-01T00:00:00.000Z</td>\n",
       "      <td>[{'contract_address': '0xe0b9bcd54bf8a730ea5d3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>1250</td>\n",
       "      <td>Zurcoin</td>\n",
       "      <td>ZUR</td>\n",
       "      <td>coin</td>\n",
       "      <td>Zurcoin (ZUR) is a cryptocurrency . Users are ...</td>\n",
       "      <td>zurcoin</td>\n",
       "      <td></td>\n",
       "      <td>[mineable, pow, quark]</td>\n",
       "      <td>[Mineable, PoW, Quark]</td>\n",
       "      <td>[OTHERS, ALGORITHM, ALGORITHM]</td>\n",
       "      <td>2016-05-09T00:00:00.000Z</td>\n",
       "      <td>DmhZur</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>106031475.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3.481553e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>1389</td>\n",
       "      <td>Zayedcoin</td>\n",
       "      <td>ZYD</td>\n",
       "      <td>coin</td>\n",
       "      <td>Zayedcoin (ZYD) is a cryptocurrency . Users ar...</td>\n",
       "      <td>zayedcoin</td>\n",
       "      <td></td>\n",
       "      <td>[mineable, pow, sha-256]</td>\n",
       "      <td>[Mineable, PoW, SHA-256]</td>\n",
       "      <td>[OTHERS, ALGORITHM, ALGORITHM]</td>\n",
       "      <td>2016-09-17T00:00:00.000Z</td>\n",
       "      <td>ZayedCoin</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1046 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        name symbol category  \\\n",
       "0       93     42-coin     42     coin   \n",
       "1     2837   0xBitcoin  0xBTC    token   \n",
       "2     2601      1World    1WO    token   \n",
       "3     1252       2GIVE  2GIVE     coin   \n",
       "4     3287     Abulaba    AAA    token   \n",
       "...    ...         ...    ...      ...   \n",
       "1041  1896          0x    ZRX    token   \n",
       "1042  2047  Zeusshield    ZSC    token   \n",
       "1043  4826   ZUM TOKEN    ZUM    token   \n",
       "1044  1250     Zurcoin    ZUR     coin   \n",
       "1045  1389   Zayedcoin    ZYD     coin   \n",
       "\n",
       "                                            description        slug  \\\n",
       "0     42-coin (42) is a cryptocurrency . Users are a...     42-coin   \n",
       "1     0xBitcoin (0xBTC) is a cryptocurrency and oper...       0xbtc   \n",
       "2     1World (1WO) is a cryptocurrency and operates ...      1world   \n",
       "3     2GIVE (2GIVE) is a cryptocurrency . Users are ...       2give   \n",
       "4     Abulaba (AAA) is a cryptocurrency and operates...     abulaba   \n",
       "...                                                 ...         ...   \n",
       "1041  0x (ZRX) is a cryptocurrency and operates on t...          0x   \n",
       "1042  Zeusshield (ZSC) is a cryptocurrency and opera...  zeusshield   \n",
       "1043  ZUM TOKEN (ZUM) is a cryptocurrency launched i...   zum-token   \n",
       "1044  Zurcoin (ZUR) is a cryptocurrency . Users are ...     zurcoin   \n",
       "1045  Zayedcoin (ZYD) is a cryptocurrency . Users ar...   zayedcoin   \n",
       "\n",
       "      subreddit                                               tags  \\\n",
       "0                [mineable, hybrid-pow-pos, scrypt, store-of-va...   \n",
       "1     0xbitcoin                      [mineable, arbitrum-ecosytem]   \n",
       "2                                             [algorand-ecosystem]   \n",
       "3         2GIVE                 [mineable, hybrid-pow-pos, scrypt]   \n",
       "4                                                             None   \n",
       "...         ...                                                ...   \n",
       "1041  0xProject  [platform, decentralized-exchange-dex-token, d...   \n",
       "1042                               [asset-management, ai-big-data]   \n",
       "1043                               [ethereum-ecosystem, bnb-chain]   \n",
       "1044                                        [mineable, pow, quark]   \n",
       "1045                                      [mineable, pow, sha-256]   \n",
       "\n",
       "                                              tag-names  \\\n",
       "0     [Mineable, Hybrid - PoW & PoS, Scrypt, Store O...   \n",
       "1                        [Mineable, Arbitrum Ecosystem]   \n",
       "2                                  [Algorand Ecosystem]   \n",
       "3                [Mineable, Hybrid - PoW & PoS, Scrypt]   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "1041  [Platform, Decentralized Exchange (DEX) Token,...   \n",
       "1042                  [Asset Management, AI & Big Data]   \n",
       "1043                    [Ethereum Ecosystem, BNB Chain]   \n",
       "1044                             [Mineable, PoW, Quark]   \n",
       "1045                           [Mineable, PoW, SHA-256]   \n",
       "\n",
       "                                             tag-groups  \\\n",
       "0              [OTHERS, ALGORITHM, ALGORITHM, CATEGORY]   \n",
       "1                                    [OTHERS, PLATFORM]   \n",
       "2                                            [CATEGORY]   \n",
       "3                        [OTHERS, ALGORITHM, ALGORITHM]   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "1041  [CATEGORY, CATEGORY, CATEGORY, CATEGORY, CATEG...   \n",
       "1042                               [INDUSTRY, INDUSTRY]   \n",
       "1043                               [PLATFORM, PLATFORM]   \n",
       "1044                     [OTHERS, ALGORITHM, ALGORITHM]   \n",
       "1045                     [OTHERS, ALGORITHM, ALGORITHM]   \n",
       "\n",
       "                    date_added twitter_username  is_hidden  \\\n",
       "0     2014-01-14T00:00:00.000Z       42newchain          0   \n",
       "1     2018-06-04T00:00:00.000Z  0xBTCFoundation          0   \n",
       "2     2018-03-21T00:00:00.000Z    1World_Online          0   \n",
       "3     2016-05-16T00:00:00.000Z        2GiveCoin          0   \n",
       "4     2018-09-14T00:00:00.000Z   AbulabaCapital          0   \n",
       "...                        ...              ...        ...   \n",
       "1041  2017-08-16T00:00:00.000Z        0xproject          0   \n",
       "1042  2017-10-13T00:00:00.000Z       Zeusshield          0   \n",
       "1043  2019-10-25T00:00:00.000Z        Zum_Token          0   \n",
       "1044  2016-05-09T00:00:00.000Z           DmhZur          0   \n",
       "1045  2016-09-17T00:00:00.000Z        ZayedCoin          0   \n",
       "\n",
       "                 date_launched  \\\n",
       "0                         None   \n",
       "1                         None   \n",
       "2                         None   \n",
       "3                         None   \n",
       "4                         None   \n",
       "...                        ...   \n",
       "1041                      None   \n",
       "1042                      None   \n",
       "1043  2019-09-01T00:00:00.000Z   \n",
       "1044                      None   \n",
       "1045                      None   \n",
       "\n",
       "                                       contract_address  \\\n",
       "0     [{'contract_address': '0x73cf73c2503154de4dc12...   \n",
       "1     [{'contract_address': '0xb6ed7644c69416d67b522...   \n",
       "2     [{'contract_address': '0xfdbc1adc26f0f8f8606a5...   \n",
       "3                                                    []   \n",
       "4     [{'contract_address': '0xd938137e6d96c72e4a608...   \n",
       "...                                                 ...   \n",
       "1041  [{'contract_address': '0xe41d2489571d322189246...   \n",
       "1042  [{'contract_address': '0x7A41e0517a5ecA4FdbC7F...   \n",
       "1043  [{'contract_address': '0xe0b9bcd54bf8a730ea5d3...   \n",
       "1044                                                 []   \n",
       "1045                                                 []   \n",
       "\n",
       "      self_reported_circulating_supply self_reported_tags  \\\n",
       "0                                  NaN               None   \n",
       "1                            8183550.0               None   \n",
       "2                                  NaN               None   \n",
       "3                                  NaN               None   \n",
       "4                                  NaN               None   \n",
       "...                                ...                ...   \n",
       "1041                               NaN               None   \n",
       "1042                               NaN               None   \n",
       "1043                               NaN               None   \n",
       "1044                       106031475.0               None   \n",
       "1045                               NaN               None   \n",
       "\n",
       "      self_reported_market_cap  \n",
       "0                          NaN  \n",
       "1                 1.896847e+06  \n",
       "2                          NaN  \n",
       "3                          NaN  \n",
       "4                          NaN  \n",
       "...                        ...  \n",
       "1041                       NaN  \n",
       "1042                       NaN  \n",
       "1043                       NaN  \n",
       "1044              3.481553e+04  \n",
       "1045                       NaN  \n",
       "\n",
       "[1046 rows x 18 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get average price entire of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/30 03:58:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "BINANCE_API_KEY = os.environ.get(\"BINANCE_API_KEY\")\n",
    "BINANCE_API_SECRET = os.environ.get(\"BINANCE_API_SECRET\")\n",
    "client = Spot(key=BINANCE_API_KEY, secret=BINANCE_API_SECRET)\n",
    "spark = ps.SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-notebook\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"4096m\").\\\n",
    "        getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get symbols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchanges = client.exchange_info()\n",
    "symbols = list(map(lambda item: item.get('symbol'), exchanges.get('symbols')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get prices of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = client.ticker_24hr(symbols=symbols[:500])\n",
    "data2 = client.ticker_24hr(symbols=symbols[500:1000])\n",
    "data3 = client.ticker_24hr(symbols=symbols[1000:1500])\n",
    "data4 = client.ticker_24hr(symbols=symbols[1500:2000])\n",
    "data5 = client.ticker_24hr(symbols=symbols[2000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather and store in hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [*data1, *data2, *data3, *data4, *data5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pyspark/sql/pandas/conversion.py:327: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------------------+----------------+--------------+----------+----------+----------+-----------+----------+----------+----------+----------+----------+---------------+-------------+-------------+-------------+---------+---------+------+\n",
      "|symbol|priceChange|priceChangePercent|weightedAvgPrice|prevClosePrice| lastPrice|   lastQty|  bidPrice|     bidQty|  askPrice|    askQty| openPrice| highPrice|  lowPrice|         volume|  quoteVolume|     openTime|    closeTime|  firstId|   lastId| count|\n",
      "+------+-----------+------------------+----------------+--------------+----------+----------+----------+-----------+----------+----------+----------+----------+----------+---------------+-------------+-------------+-------------+---------+---------+------+\n",
      "|ETHBTC| 0.00239200|             3.289|      0.07406409|    0.07272400|0.07511200|0.57140000|0.07511100|28.58110000|0.07511200|1.68350000|0.07272000|0.07598000|0.07250300|103556.38150000|7669.80952961|1669692918173|1669779318173|392960904|393177510|216607|\n",
      "+------+-----------+------------------+----------------+--------------+----------+----------+----------+-----------+----------+----------+----------+----------+----------+---------------+-------------+-------------+-------------+---------+---------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o71.parquet.\n: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create directory /test/test.parquet/_temporary/0. Name node is in safe mode.\nThe reported blocks 0 needs additional 205586 blocks to reach the threshold 0.9990 of total blocks 205792.\nThe minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:hadoop-namenode\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1508)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1495)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3256)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1163)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:723)\n\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:549)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:518)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)\n\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1476)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1413)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n\tat com.sun.proxy.$Proxy24.mkdirs(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:563)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n\tat com.sun.proxy.$Proxy25.mkdirs(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:3005)\n\tat org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2975)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$21.doCall(DistributedFileSystem.java:1047)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$21.doCall(DistributedFileSystem.java:1043)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1061)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1036)\n\tat org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1881)\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:313)\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.setupJob(HadoopMapReduceCommitProtocol.scala:163)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:168)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:178)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:122)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:121)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:944)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:944)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:396)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:380)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:269)\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:829)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhdfs://namenode:9000/test/test.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/readwriter.py:936\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[0;32m--> 936\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/utils.py:131\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    133\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o71.parquet.\n: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create directory /test/test.parquet/_temporary/0. Name node is in safe mode.\nThe reported blocks 0 needs additional 205586 blocks to reach the threshold 0.9990 of total blocks 205792.\nThe minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:hadoop-namenode\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1508)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1495)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3256)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1163)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:723)\n\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:549)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:518)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)\n\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1476)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1413)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n\tat com.sun.proxy.$Proxy24.mkdirs(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:563)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n\tat com.sun.proxy.$Proxy25.mkdirs(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:3005)\n\tat org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2975)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$21.doCall(DistributedFileSystem.java:1047)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$21.doCall(DistributedFileSystem.java:1043)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1061)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1036)\n\tat org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1881)\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:313)\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.setupJob(HadoopMapReduceCommitProtocol.scala:163)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:168)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:178)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:122)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:121)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:944)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:944)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:396)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:380)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:269)\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:829)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "df.write.option(\"header\",True) \\\n",
    "         .mode(\"overwrite\") \\\n",
    "         .parquet(f\"hdfs://namenode:9000/test/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
